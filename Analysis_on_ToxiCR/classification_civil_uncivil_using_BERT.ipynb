{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da534d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f06d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_file ='for_Train_and_validation_data.xlsx' \n",
    "df = pd.read_excel(xlsx_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_toxic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df.is_toxic.unique()\n",
    "possible_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d792c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad10c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.is_toxic.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d347c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06001f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=17, \n",
    "                                                  stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b37ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36488d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbef260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['is_toxic', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3385828",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e602c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.data_type=='train'].message.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[X_val[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276489e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[y_val[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87735a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "\n",
    "# # Replace 'model_name' with the name of the pre-trained model you're using\n",
    "# model_name = 'bert-base-uncased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Assuming you have a DataFrame named 'df'\n",
    "# for index, row in df.iterrows():\n",
    "#     data_type = row['data_type']\n",
    "#     message = row['message']\n",
    "#     label = row['label']\n",
    "\n",
    "#     encoded_data = tokenizer.encode_plus(\n",
    "#         text=message,\n",
    "#         add_special_tokens=True,\n",
    "#         return_attention_mask=True,\n",
    "#         pad_to_max_length=True,\n",
    "#         max_length=256,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "\n",
    "#     input_ids = encoded_data['input_ids']\n",
    "#     attention_mask = encoded_data['attention_mask']\n",
    "    \n",
    "#     #print(f\"Processing row {index + 1} - Data Type: {data_type}, Message: {message}, Label: {label}\")\n",
    "    \n",
    "#     # Here you can proceed with storing or processing 'input_ids', 'attention_mask', and 'label'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00940b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].message.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=1024, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].message.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=1024, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf04ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff5eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ab05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c94701",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f127f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bfc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe92cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8835969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)             \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_flat = np.argmax(predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6729845",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81149d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('ToxiCR_BERT.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2471037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed27f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions), len(true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dff5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(preds_flat, true_vals))\n",
    "print(\"Precision:\",metrics.precision_score(preds_flat, true_vals))\n",
    "print(\"Recall:\",metrics.recall_score(preds_flat, true_vals))\n",
    "print(\"f1 score\", metrics.f1_score(preds_flat, true_vals, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58dfad4",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_file ='prediction_github_projectsComment/aggregated_data.csv' \n",
    "#df_test = pd.read_excel(xlsx_file)\n",
    "df_test = pd.read_csv(xlsx_file)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df_test.is_toxic.unique()\n",
    "possible_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = df_test.is_toxic.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_val = tokenizer.batch_encode_plus(\n",
    "    df_test.message.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = encoded_test_val['input_ids']\n",
    "attention_masks_test = encoded_test_val['attention_mask']\n",
    "labels_test = torch.tensor(df_test.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test,labels_test)\n",
    "batch_size = 32\n",
    "dataloader_test = DataLoader(dataset_test, \n",
    "                                   sampler=SequentialSampler(dataset_test), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c181b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataloader_test):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for batch in dataloader_test:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':         batch[2],\n",
    "                }  \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        logits = outputs[1]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ecc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = test_model(dataloader_test) \n",
    "preds_flat_test = np.argmax(pred_test, axis=1).flatten()\n",
    "print(preds_flat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3699da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_data = pd.DataFrame(preds_flat_test, columns = [\"prediction\"])\n",
    "pd_cont = pd.concat([df_test[\"message\"], pred_data], axis = 1)\n",
    "pd_cont.to_csv(\"prediction_github_comments_byToxicR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ec1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3667e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slice = df_test[\"message\"]\n",
    "df_slice.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_cont_rst = pd.concat([df_slice.reset_index(), pred_data], axis = 1)\n",
    "pd_cont_rst.to_csv(\"done.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be0a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic_gru",
   "language": "python",
   "name": "toxic_gru"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
