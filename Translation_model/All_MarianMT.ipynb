{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebcee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb25bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataloader_test):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for batch in dataloader_test:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':         batch[2],\n",
    "                }  \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        logits = outputs[1]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(df):\n",
    "    \n",
    "    encoded_test_val = tokenizer.batch_encode_plus(\n",
    "     df.message.values, \n",
    "     add_special_tokens=True, \n",
    "     return_attention_mask=True, \n",
    "     pad_to_max_length=True, \n",
    "     max_length=512, \n",
    "     return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids_test = encoded_test_val['input_ids']\n",
    "    attention_masks_test = encoded_test_val['attention_mask']\n",
    "    labels_test = torch.tensor(df.label.values)\n",
    "\n",
    "    dataset_test = TensorDataset(input_ids_test, attention_masks_test,labels_test)\n",
    "    batch_size = 8\n",
    "    dataloader_test = DataLoader(dataset_test, \n",
    "                                    sampler=SequentialSampler(dataset_test), \n",
    "                                    batch_size=batch_size)\n",
    "\n",
    "\n",
    "    pred_test = test_model(dataloader_test) \n",
    "    preds_flat_test = np.argmax(pred_test, axis=1).flatten()\n",
    "    return preds_flat_test\n",
    "#     #print(preds_flat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Set the logging level for the transformers module\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "# Suppress specific FutureWarning messages\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"The `pad_to_max_length` argument is deprecated*\")\n",
    "\n",
    "# Initialize an empty list to store comments\n",
    "comments = []\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
    "                                          do_lower_case=True)\n",
    "label_dict = {0: 0, 1: 1}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                          num_labels=len(label_dict),\n",
    "                                                          output_attentions=False,\n",
    "                                                          output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('MyModel_BERT_epoch_4.model', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "# Load the fine-tuned MarianMT model\n",
    "fine_tuned_marian_model = MarianMTModel.from_pretrained(\"marian_output\")\n",
    "tokenizer_Marian = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ROMANCE\")\n",
    "\n",
    "input_csv_file = \"/home/mdr614/Toxic_GRU/Fresh/random2000_for_sentimentAnalysis.csv\"  # Replace with your CSV file path\n",
    "comments_df = pd.read_csv(input_csv_file, header=None, names=[\"comment\"])\n",
    "\n",
    "# Create an empty list to store comments and their associated outputs\n",
    "comments_with_outputs = []\n",
    "\n",
    "count=0\n",
    "for inp_sentence in comments_df[\"comment\"]:\n",
    "    # Collect comment from the user or exit the loop\n",
    "    comment = inp_sentence\n",
    "\n",
    "    # Add the comment to the list\n",
    "    comments.append(comment)\n",
    "\n",
    "    # Create a pandas DataFrame from the collected comments\n",
    "    data = {'message': comments, 'label': 0}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    #for MarianMT\n",
    "    uncivil_sentence = comment\n",
    "    inputs = tokenizer_Marian(uncivil_sentence, return_tensors=\"pt\", max_length=1024, trancation=True)\n",
    "    generated_ids = fine_tuned_marian_model.generate(**inputs, max_new_tokens=1024)\n",
    "    generated_civil_sentence = tokenizer_Marian.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    subword_units = generated_civil_sentence.split('‚ñÅ')\n",
    "    # Remove empty strings resulting from the split\n",
    "    subword_units = [unit for unit in subword_units if unit]\n",
    "    # Join subword units into words\n",
    "    cleaned_sentence = ' '.join(subword_units)\n",
    "\n",
    "                    # Add the comment to the list\n",
    "    comments.append(cleaned_sentence)\n",
    "    # Create a pandas DataFrame from the collected comments\n",
    "    data = {'message': comments, 'label': 0}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    preds_flat_test = detection(df)\n",
    "\n",
    "    if preds_flat_test[-1]==0:\n",
    "        print(\"\\033[92mGenerated civil alternative-MarianMT:\\033[0m\", cleaned_sentence)\n",
    "        comments_with_outputs.append((comment, cleaned_sentence))\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(\"\\033[91mGenerated civil alternative-MarianMT:\\033[0m\", cleaned_sentence)\n",
    "        comments_with_outputs.append((comment, \"Not Generated\"))\n",
    "        print(\"\\n\")\n",
    "\n",
    "    count+=1\n",
    "    print(\"count:\", count)\n",
    "\n",
    "output_df = pd.DataFrame(comments_with_outputs, columns=[\"uncivil\", \"civil\"])\n",
    "output_csv_file = \"/content/drive/MyDrive/civilAlternatives_by_MarianMT_random2000.csv\"\n",
    "output_df.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a206f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic_gru",
   "language": "python",
   "name": "toxic_gru"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
